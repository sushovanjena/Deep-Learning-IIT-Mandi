{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read the linearly seperable classification dataset files and prepare the data for training, testing, and validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import collections\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# reading all images in a directory\n",
    "path1 = r\"D:\\Sujeet_PhD\\Course_Work\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Classification\\Image_Group32\\train\\movie_theater_indoor\"\n",
    "path2 = r\"D:\\Sujeet_PhD\\Course_Work\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Classification\\Image_Group32\\train\\rock_arch\"\n",
    "path3 = r\"D:\\Sujeet_PhD\\Course_Work\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Classification\\Image_Group32\\train\\valley\"\n",
    "path4 = r\"D:\\Sujeet_PhD\\Course_Work\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Classification\\Image_Group32\\test\\movie_theater_indoor\"\n",
    "path5 = r\"D:\\Sujeet_PhD\\Course_Work\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Classification\\Image_Group32\\test\\rock_arch\"\n",
    "path6 = r\"D:\\Sujeet_PhD\\Course_Work\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Classification\\Image_Group32\\test\\valley\"\n",
    "\n",
    "dirs1 = os.listdir(path1)\n",
    "dirs2 = os.listdir(path2)\n",
    "dirs3 = os.listdir(path3)\n",
    "dirs4 = os.listdir(path4)\n",
    "dirs5 = os.listdir(path5)\n",
    "dirs6 = os.listdir(path6)\n",
    "\n",
    "BoVW_train_class1, BoVW_train_class2, BoVW_train_class3 = [], [], []\n",
    "BoVW_test_class1, BoVW_test_class2, BoVW_test_class3 = [], [], []\n",
    "\n",
    "def BoVW_feature(dirs, path, BoVW_class):\n",
    "    windowsize_r = 32\n",
    "    windowsize_c = 32\n",
    "    for file in dirs:\n",
    "        img = cv2.imread(os.path.join(path, file), 1)\n",
    "        [h, w, c] = img.shape\n",
    "        patches = []\n",
    "        store_patch = []\n",
    "        patch_vec = []\n",
    "        for r in range(0, h - windowsize_r, windowsize_r):\n",
    "            for c in range(0, w - windowsize_c, windowsize_c):\n",
    "                window = img[r:r+windowsize_r, c:c+windowsize_c]\n",
    "                patches.append(window)\n",
    "        for r in range(0, h - windowsize_r, windowsize_r):\n",
    "            window = img[r:r+windowsize_r, w-windowsize_c:w]\n",
    "            patches.append(window)\n",
    "        for c in range(0, w - windowsize_c, windowsize_c):\n",
    "            window = img[h-windowsize_r:h, c:c+windowsize_c]\n",
    "            patches.append(window)\n",
    "        window = img[h-windowsize_r:h, w-windowsize_c:w]\n",
    "        patches.append(window)\n",
    "            \n",
    "        for j in range(0, len(patches)):\n",
    "            hist_b = cv2.calcHist([patches[j]], [0], None, [8], [0, 256])\n",
    "            hist_g = cv2.calcHist([patches[j]], [1], None, [8], [0, 256])\n",
    "            hist_r = cv2.calcHist([patches[j]], [2], None, [8], [0, 256])\n",
    "            hist = np.concatenate((hist_b, hist_g, hist_r))\n",
    "            store_patch.append(hist.T[0])\n",
    "        \n",
    "        kmeans = KMeans(n_clusters = 32, random_state = 0).fit(np.array(store_patch))\n",
    "        patch_vec = kmeans.predict(np.array(store_patch))\n",
    "        counter = list(collections.Counter(patch_vec).values())\n",
    "        BoVW_class.append(counter)\n",
    "                \n",
    "### Call BoVW_feature function to prepare the BoVW dataset from images of all classes\n",
    "BoVW_feature(dirs1, path1, BoVW_train_class1)\n",
    "BoVW_feature(dirs2, path2, BoVW_train_class2)\n",
    "BoVW_feature(dirs3, path3, BoVW_train_class3)\n",
    "BoVW_feature(dirs4, path4, BoVW_test_class1)\n",
    "BoVW_feature(dirs5, path5, BoVW_test_class2)\n",
    "BoVW_feature(dirs6, path6, BoVW_test_class3)\n",
    "\n",
    "### Create data set by combining all three class data\n",
    "def all_class_data(train1, train2, train3, validate1, validate2, validate3, test1, test2, test3):\n",
    "    trainX = np.concatenate((train1, train2, train3), axis=0)\n",
    "    trainY = np.array([0 for i in range(len(train1))] + [1 for i in range(len(train2))] + [2 for i in range(len(train3))])\n",
    "    validateX = np.concatenate((validate1, validate2, validate3), axis=0)\n",
    "    validateY = np.array([0 for i in range(len(validate1))] + [1 for i in range(len(validate2))] + [2 for i in range(len(validate3))])\n",
    "    testX = np.concatenate((test1, test2, test3), axis=0)\n",
    "    testY = np.array([0 for i in range(len(test1))] + [1 for i in range(len(test2))] + [2 for i in range(len(test3))])\n",
    "    return trainX, trainY, validateX, validateY, testX, testY\n",
    "\n",
    "### Devide the Class data into training, validation, and testing data\n",
    "train1, validate1 = np.split(np.array(BoVW_train_class1), [int(0.8*len(BoVW_train_class1))])\n",
    "test1 = np.array(BoVW_test_class1)\n",
    "### Devide the Class2 data into training, validation, and testing data\n",
    "train2, validate2 = np.split(np.array(BoVW_train_class2), [int(0.8*len(BoVW_train_class2))])\n",
    "test2 = np.array(BoVW_test_class2)\n",
    "### Devide the Class3 data into training, validation, and testing data\n",
    "train3, validate3 = np.split(np.array(BoVW_train_class3), [int(0.8*len(BoVW_train_class3))])\n",
    "test3 = np.array(BoVW_test_class3)\n",
    "trainX, trainY, validateX, validateY, testX, testY = all_class_data(train1, train2, train3, validate1, validate2, validate3, test1, test2, test3)\n",
    "\n",
    "### Convert label data to one hot encoder\n",
    "### 0 -> (1, 0, 0), 1 -> (0, 1, 0), 2 -> (0, 0, 1)\n",
    "enc = OneHotEncoder()\n",
    "y_OHE_train = enc.fit_transform(np.expand_dims(trainY,1)).toarray()\n",
    "y_OHE_val = enc.fit_transform(np.expand_dims(validateY,1)).toarray()\n",
    "y_OHE_test = enc.fit_transform(np.expand_dims(testY,1)).toarray()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Implementation of multilayer feed forward neural network (MLFFNN)</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.] [0.01204232 0.1219622  0.8793246 ]\n",
      "[1. 0. 0.] [0.00177521 0.76258958 0.57435438]\n",
      "[1. 0. 0.] [0.53628919 0.08837069 0.06590816]\n",
      "[1. 0. 0.] [0.00275335 0.13820374 0.96589472]\n",
      "[1. 0. 0.] [0.00328482 0.08865551 0.97398237]\n",
      "[1. 0. 0.] [0.49172007 0.01524636 0.39051158]\n",
      "[1. 0. 0.] [0.99911139 0.00407186 0.00112187]\n",
      "[1. 0. 0.] [0.00286931 0.15785921 0.95641476]\n",
      "[1. 0. 0.] [0.12885456 0.0070249  0.9230571 ]\n",
      "[1. 0. 0.] [0.09517114 0.07054218 0.59313538]\n",
      "[0. 1. 0.] [0.10582344 0.09138958 0.45625566]\n",
      "[0. 1. 0.] [0.1092762  0.00560365 0.95203018]\n",
      "[0. 1. 0.] [6.84010322e-04 9.98379099e-01 1.02150425e-02]\n",
      "[0. 1. 0.] [0.12084402 0.68674333 0.01759625]\n",
      "[0. 1. 0.] [0.0661278  0.01794275 0.88484413]\n",
      "[0. 1. 0.] [0.72475653 0.03549654 0.08897108]\n",
      "[0. 1. 0.] [0.00449028 0.06889598 0.97339825]\n",
      "[0. 1. 0.] [0.00209922 0.09619329 0.98426839]\n",
      "[0. 1. 0.] [0.58225978 0.01721745 0.24751539]\n",
      "[0. 1. 0.] [0.0281348  0.98473555 0.00181299]\n",
      "[0. 0. 1.] [0.0022039  0.99747546 0.00471701]\n",
      "[0. 0. 1.] [0.02971879 0.86395322 0.02617499]\n",
      "[0. 0. 1.] [0.99463635 0.00494539 0.00667772]\n",
      "[0. 0. 1.] [9.11243350e-04 1.75755350e-01 9.85050993e-01]\n",
      "[0. 0. 1.] [0.01491329 0.2762178  0.61787717]\n",
      "[0. 0. 1.] [0.39897988 0.00900818 0.68538776]\n",
      "[0. 0. 1.] [9.93544985e-01 3.42147126e-01 4.37834792e-05]\n",
      "[0. 0. 1.] [4.72029002e-02 9.95262270e-01 2.82803190e-04]\n",
      "[0. 0. 1.] [0.48256501 0.00237886 0.84140265]\n",
      "[0. 0. 1.] [0.51149626 0.05488594 0.15578593]\n",
      "Confusion Matrix of training data: [[40.  0.  0.]\n",
      " [ 0. 40.  0.]\n",
      " [ 0.  0. 40.]]\n",
      "Classification Accuracy of training data: 100.0\n",
      "Confusion Matrix of validation data: [[3. 1. 6.]\n",
      " [2. 3. 5.]\n",
      " [3. 3. 4.]]\n",
      "Classification Accuracy of Validation data: 33.333333333333336\n",
      "Confusion Matrix of test data: [[20. 11. 19.]\n",
      " [17. 13. 20.]\n",
      " [20.  9. 21.]]\n",
      "Classification Accuracy of test data: 36.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "### Activation Functions Definitions\n",
    "class Sigmoid():\n",
    "    def __call__(self, x, b=1):\n",
    "        return 1.0/(1.0 + np.exp(-(b*x)))\n",
    "    def gradient(self, x, b=1):\n",
    "        return self.__call__(x, b) * (1 - self.__call__(x, b))\n",
    "\n",
    "class Linear():\n",
    "    def __call__(self, x, b=1):\n",
    "        return b*x\n",
    "    def gradient(self, x, b=1):\n",
    "        return b\n",
    "\n",
    "### Multilayer feed forward neural network class\n",
    "class MLFFNN():\n",
    "    def __init__(self, n_hidden, n_epoch=1000, learning_rate=0.01, threshold=0.001):\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_epoch = n_epoch\n",
    "        self.learning_rate = learning_rate\n",
    "        self.threshold = threshold\n",
    "        self.hidden_activation = Sigmoid()\n",
    "        self.output_activation = Sigmoid()\n",
    "\n",
    "    ### Initialize the weights of neural network\n",
    "    def initialize_weights(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        _, n_outputs = y.shape\n",
    "        \n",
    "        ### For all hidden layers\n",
    "        pre_num_of_neuron = n_features\n",
    "        self.weights = {}\n",
    "        self.w0 = {}\n",
    "        for i in range(len(self.n_hidden)):\n",
    "            limit   = 1 / math.sqrt(pre_num_of_neuron/2)\n",
    "            self.weights[i]  = np.random.uniform(-limit, limit, (pre_num_of_neuron, self.n_hidden[i]))\n",
    "            self.w0[i] = np.random.uniform(-limit, limit, (1, self.n_hidden[i]))\n",
    "            pre_num_of_neuron = self.n_hidden[i]\n",
    "        \n",
    "        # For output layer\n",
    "        limit   = 1 / math.sqrt(pre_num_of_neuron/2)\n",
    "        self.V  = np.random.uniform(-limit, limit, (self.n_hidden[-1], n_outputs))\n",
    "        self.v0 = np.random.uniform(-limit, limit, (1, n_outputs))\n",
    "\n",
    "    def train(self, X, y, epoch=True):\n",
    "        self.initialize_weights(X, y)\n",
    "        self.errors = []\n",
    "        ### This conditional block of code is for fixed number of epoch\n",
    "        if epoch == True:\n",
    "            ### Run it for n_epoch times\n",
    "            for i in range(self.n_epoch):\n",
    "                ### For hidden layer\n",
    "                inputs = X\n",
    "#                 ### Randomize the input data\n",
    "#                 rand_index = np.random.permutation(len(inputs))\n",
    "#                 inputs = inputs[rand_index]\n",
    "#                 y = y[rand_index]\n",
    "                \n",
    "                self.hidden_input = {}\n",
    "                self.hidden_output = {}\n",
    "                ### Forward Calculation ###\n",
    "                self.forward_calculation(inputs)\n",
    "                ### Backpropagation Calculation ###\n",
    "                self.backpropagation_calculation(inputs, y)\n",
    "\n",
    "                ### Store average instantaneous errors for each epoch\n",
    "                self.errors.append(np.sum(self.SquareLoss(y, self.y_pred))/y.shape[0])\n",
    "        ### This conditional block of code is for fixed threshold of average error\n",
    "        else:\n",
    "            error = 10000000\n",
    "            noOfNoChangeError = 0\n",
    "            ### Run it until error converges to the threshhold\n",
    "            while error > self.threshold:\n",
    "                ### For hidden layer\n",
    "                inputs = X\n",
    "#                 ### Randomize the input data\n",
    "#                 rand_index = np.random.permutation(len(inputs))\n",
    "#                 inputs = inputs[rand_index]\n",
    "#                 y = y[rand_index]\n",
    "                \n",
    "                self.hidden_input = {}\n",
    "                self.hidden_output = {}\n",
    "                ### Forward Calculation ###\n",
    "                self.forward_calculation(inputs)\n",
    "                ### Backpropagation Calculation ###\n",
    "                self.backpropagation_calculation(inputs, y)\n",
    "                \n",
    "                ### Store average instantaneous errors for each epoch\n",
    "                self.errors.append(np.sum(self.SquareLoss(y, self.y_pred))/y.shape[0])\n",
    "                ### If there is no change in error\n",
    "                if noOfNoChangeError >=20:\n",
    "                    break\n",
    "                else:\n",
    "                    if len(self.errors) >= 4:\n",
    "                        if error == self.errors[-1] and error == self.errors[-2]:\n",
    "                            noOfNoChangeError += 1\n",
    "                error = self.errors[-1]\n",
    "                \n",
    "    ### Forward Calculation ###\n",
    "    def forward_calculation(self, inputs):\n",
    "        ### For hidden layer\n",
    "        for i in range(len(self.n_hidden)):\n",
    "            ### Input to neuron\n",
    "            self.hidden_input[i] = inputs.dot(self.weights[i]) + self.w0[i]\n",
    "            ### Output of neuron\n",
    "            self.hidden_output[i] = self.hidden_activation(self.hidden_input[i])\n",
    "            inputs = self.hidden_output[i]\n",
    "        ### For output layer\n",
    "        self.output_layer_input = inputs.dot(self.V) + self.v0\n",
    "        self.y_pred = self.output_activation(self.output_layer_input)\n",
    "        return self.y_pred\n",
    "    \n",
    "    ### Backpropagation Calculation ###\n",
    "    def backpropagation_calculation(self, inputs, y):\n",
    "        ### First for output layer\n",
    "        ### Gradient w.r.t input of output layer\n",
    "        grad_wrt_out_l_input = self.loss(y, self.y_pred) * self.output_activation.gradient(self.output_layer_input)\n",
    "        grad_v = self.hidden_output[len(self.n_hidden)-1].T.dot(grad_wrt_out_l_input)\n",
    "        grad_v0 = np.sum(grad_wrt_out_l_input, axis=0, keepdims=True)\n",
    "        ### For hidden layer\n",
    "        ### Gradient w.r.t input of hidden layer\n",
    "        next_grad_wrt_hidden_l_input = grad_wrt_out_l_input\n",
    "        next_weight = self.V\n",
    "        prev_input = inputs\n",
    "        grad_w = {}\n",
    "        grad_w0 = {}\n",
    "        ### Calculation for multiple hidden layer starting from last to first hidden layer\n",
    "        for i in reversed(range(len(self.n_hidden))):\n",
    "            grad_wrt_hidden_l_input = next_grad_wrt_hidden_l_input.dot(next_weight.T) * self.hidden_activation.gradient(self.hidden_input[i])\n",
    "            ### If hidden layer not connected to input layer\n",
    "            if i != 0:\n",
    "                grad_w[i] = self.hidden_output[i-1].T.dot(grad_wrt_hidden_l_input)\n",
    "            ### when hidden layer connected to input layer\n",
    "            else:\n",
    "                grad_w[i] = inputs.T.dot(grad_wrt_hidden_l_input)\n",
    "            grad_w0[i] = np.sum(grad_wrt_hidden_l_input, axis=0, keepdims=True)\n",
    "            next_grad_wrt_hidden_l_input = grad_wrt_hidden_l_input\n",
    "            next_weight = self.weights[i]\n",
    "\n",
    "        ### Calculaton for weights update ###\n",
    "        ### Weights update of output layer\n",
    "        self.V  -= self.learning_rate * grad_v\n",
    "        self.v0 -= self.learning_rate * grad_v0\n",
    "        ### Weights update of hidden layers\n",
    "        for i in range(len(self.n_hidden)):\n",
    "            self.weights[i]  -= self.learning_rate * grad_w[i]\n",
    "            self.w0[i] -= self.learning_rate * grad_w0[i]\n",
    "    \n",
    "    ### Prediction Function\n",
    "    def predict(self, X):\n",
    "        ### Call Forward Calculation ###\n",
    "        y_pred = self.forward_calculation(X)\n",
    "        return y_pred\n",
    "    \n",
    "    ### Instantaneous error and loss function\n",
    "    def SquareLoss(self, y, y_pred):\n",
    "        return 0.5 * np.power((y - y_pred), 2)\n",
    "    def loss(self, y, y_pred):\n",
    "        return -(y - y_pred)\n",
    "\n",
    "### Calculate the accuracy\n",
    "def accuracy_score(y, y_pred):\n",
    "    accuracy = np.sum(y == y_pred, axis=0) / len(y)\n",
    "    return accuracy*100\n",
    "\n",
    "### To calculate the confusion matrix and classification accuracy\n",
    "def confusion_matrix(actual, predicted):\n",
    "    cm = np.zeros((3, 3))\n",
    "    for i, j in zip(actual, predicted):\n",
    "        cm[i][j] += 1\n",
    "    ### For classification accuracy\n",
    "    accuracy = np.sum(actual == predicted) * 100.0 / float(len(actual))\n",
    "    return cm, accuracy\n",
    "\n",
    "### Plot of Epoch vs Mean Square Error\n",
    "def epochVsError_plot(model):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    error = model.errors\n",
    "    nepoch = [i+1 for i in range(len(error))]\n",
    "    plt.scatter(nepoch, error, marker='o', s=5, facecolors='b', edgecolors='b')\n",
    "    plt.xlabel('Number of Epoch')\n",
    "    plt.ylabel('Average Error')\n",
    "#     plt.title('Average error vs number of epoch for training of Image Classification data using MLFFNN')\n",
    "    plt.savefig(\"AvgErrorVsEpoch_MLFFNN_Image.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "### 3D scatter plot for output of each nueron of hidden layer and output layer plot\n",
    "def output_nueron_plot(X_train, y_train, z, label='hidden', layer='', nn=''):\n",
    "    # Creating figure\n",
    "    fig = plt.figure(figsize = (16, 9))\n",
    "    ax = plt.axes(projection =\"3d\")\n",
    "    # Add x, y gridlines \n",
    "    ax.grid(b = True, color ='grey', linestyle ='-.', linewidth = 0.3, alpha = 0.2) \n",
    "    # Creating color map\n",
    "    color = ['red', 'green', 'blue']\n",
    "    color_list = [color[i] for i in y_train]\n",
    "    # Creating plot\n",
    "    sctt = ax.scatter3D(X_train[:,0], X_train[:,1], z, color = color_list)\n",
    "    ax.set_xlabel('X-axis', fontweight ='bold') \n",
    "    ax.set_ylabel('Y-axis', fontweight ='bold') \n",
    "    ax.set_zlabel('Z-axis (Neuron Output) ', fontweight ='bold')\n",
    "    # save plot\n",
    "    plt.savefig(\"Output_of_{}_layer_{}_Nueron_{}_Image.png\".format(label, layer, nn), dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "def main():\n",
    "    ### Call the MLFFNN calss \n",
    "    mlffnn = MLFFNN(n_hidden=[32,32], n_epoch=10000, learning_rate=0.001, threshold=0.001)\n",
    "    ### Train the MLFFNN\n",
    "    mlffnn.train(trainX, y_OHE_train, epoch=True)\n",
    "    \n",
    "    ### Prediction for validation data\n",
    "    y_pred_train = np.argmax(mlffnn.predict(trainX), axis=1)\n",
    "    y_train = np.argmax(y_OHE_train, axis=1)\n",
    "    ### Prediction for validation data\n",
    "    y_pred_val = np.argmax(mlffnn.predict(validateX), axis=1)\n",
    "    y_val = np.argmax(y_OHE_val, axis=1)\n",
    "    y1 = mlffnn.predict(validateX)\n",
    "    for i in range(len(y_OHE_val)):\n",
    "        print(y_OHE_val[i], y1[i])\n",
    "    ### Prediction for test data\n",
    "    y_pred_test = np.argmax(mlffnn.predict(testX), axis=1)\n",
    "    y_test = np.argmax(y_OHE_test, axis=1)\n",
    "    \n",
    "    ### Calculate the accuracy and confusion matrix for validate and test data\n",
    "    CM, Accuracy = confusion_matrix(y_train, y_pred_train)\n",
    "    print(\"Confusion Matrix of training data: {}\".format(CM))\n",
    "    print(\"Classification Accuracy of training data: {}\".format(Accuracy))\n",
    "    CM, Accuracy = confusion_matrix(y_val, y_pred_val)\n",
    "    print(\"Confusion Matrix of validation data: {}\".format(CM))\n",
    "    print(\"Classification Accuracy of Validation data: {}\".format(Accuracy))\n",
    "    CM, Accuracy = confusion_matrix(y_test, y_pred_test)\n",
    "    print(\"Confusion Matrix of test data: {}\".format(CM))\n",
    "    print(\"Classification Accuracy of test data: {}\".format(Accuracy))\n",
    "\n",
    "    ### Epoch vs error plot\n",
    "    epochVsError_plot(mlffnn)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
