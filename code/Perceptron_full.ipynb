{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>For Linearly Seperable Data</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[100.   0.   0.]\n",
      " [  0. 100.   0.]\n",
      " [  0.   0. 100.]]\n",
      "Classification Accuracy: 100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from perceptron import Perceptron\n",
    "\n",
    "### Create data set by combining the two class data\n",
    "def two_class_data(train1, train2, validate1, validate2, test1, test2):\n",
    "    trainX = np.concatenate((train1, train2), axis=0)\n",
    "    trainY = np.array([0 for i in range(len(train1))] + [1 for i in range(len(train2))])\n",
    "    validateX = np.concatenate((validate1, validate2), axis=0)\n",
    "    validateY = np.array([0 for i in range(len(validate1))] + [1 for i in range(len(validate2))])\n",
    "    testX = np.concatenate((test1, test2), axis=0)\n",
    "    testY = np.array([0 for i in range(len(test1))] + [1 for i in range(len(test2))])\n",
    "    return trainX, trainY, validateX, validateY, testX, testY\n",
    "\n",
    "### Create data set by combining all three class data\n",
    "def all_class_data(train1, train2, train3, validate1, validate2, validate3, test1, test2, test3):\n",
    "    trainX = np.concatenate((train1, train2, train3), axis=0)\n",
    "    trainY = np.array([0 for i in range(len(train1))] + [1 for i in range(len(train2))] + [2 for i in range(len(train3))])\n",
    "    validateX = np.concatenate((validate1, validate2, validate3), axis=0)\n",
    "    validateY = np.array([0 for i in range(len(validate1))] + [1 for i in range(len(validate2))] + [2 for i in range(len(validate3))])\n",
    "    testX = np.concatenate((test1, test2, test3), axis=0)\n",
    "    testY = np.array([0 for i in range(len(test1))] + [1 for i in range(len(test2))] + [2 for i in range(len(test3))])\n",
    "    return trainX, trainY, validateX, validateY, testX, testY\n",
    "\n",
    "#### Path of all class dataset \n",
    "f1 = r\"D:\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Classification\\LS_Group32\\Class1.txt\"\n",
    "f2 = r\"D:\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Classification\\LS_Group32\\Class2.txt\"\n",
    "f3 = r\"D:\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Classification\\LS_Group32\\Class3.txt\"\n",
    "\n",
    "### Devide the Class1 data into training, validation, and testing data\n",
    "df = pd.read_csv(f1, delimiter=' ', header=None)\n",
    "train1, validate1, test1 = np.split(df, [int(0.6*len(df)), int(0.8*len(df))])\n",
    "### Devide the Class2 data into training, validation, and testing data\n",
    "df = pd.read_csv(f2, delimiter=' ', header=None)\n",
    "train2, validate2, test2 = np.split(df, [int(0.6*len(df)), int(0.8*len(df))])\n",
    "### Devide the Class3 data into training, validation, and testing data\n",
    "df = pd.read_csv(f3, delimiter=' ', header=None)\n",
    "train3, validate3, test3 = np.split(df, [int(0.6*len(df)), int(0.8*len(df))])\n",
    "\n",
    "#### For classification between Class1 and Class2 ####\n",
    "trainX12, trainY12, validateX12, validateY12, testX12, testY12 = two_class_data(train1, train2, validate1, validate2, test1, test2)\n",
    "trainX13, trainY13, validateX13, validateY13, testX13, testY13 = two_class_data(train1, train3, validate1, validate3, test1, test3)\n",
    "trainX23, trainY23, validateX23, validateY23, testX23, testY23 = two_class_data(train2, train3, validate2, validate3, test2, test3)\n",
    "trainX, trainY, validateX, validateY, testX, testY = all_class_data(train1, train2, train3, validate1, validate2, validate3, test1, test2, test3)\n",
    "        \n",
    "### Classification between class1 and class2 \n",
    "p12 = Perceptron(learning_rate=0.001, epoch=1000)\n",
    "p12.train(trainX12, trainY12, epoch=True)\n",
    "predictions12 = p12.predict(testX12)\n",
    "\n",
    "### Classification between class3 and class1 \n",
    "p13 = Perceptron(learning_rate=0.001, epoch=1000)\n",
    "p13.train(trainX13, trainY13, epoch=True)\n",
    "predictions13 = p13.predict(testX13)\n",
    "\n",
    "### Classification between class2 and class3 \n",
    "p23 = Perceptron(learning_rate=0.001, epoch=1000)\n",
    "p23.train(trainX23, trainY23, epoch=True)\n",
    "predictions23 = p23.predict(testX23)\n",
    "\n",
    "def predictAllClass(testX, model12, model13, model23):\n",
    "    final_pred = []\n",
    "    for i in range(len(testX)):\n",
    "        x = testX[i:i+1]\n",
    "        pred12 = model12.predict(x)\n",
    "        pred13 = model13.predict(x)\n",
    "        pred23 = model23.predict(x)\n",
    "        if pred12[0,0] == 0 and pred13[0,0] == 0 and pred23[0,0] == 0:\n",
    "            final_pred.append(0)\n",
    "        elif pred12[0,0] == 0 and pred13[0,0] == 0 and pred23[0,0] == 1:\n",
    "            final_pred.append(0)\n",
    "        elif pred12[0,0] == 0 and pred13[0,0] == 1 and pred23[0,0] == 1:\n",
    "            final_pred.append(2)\n",
    "        elif pred12[0,0] == 1 and pred13[0,0] == 0 and pred23[0,0] == 0:\n",
    "            final_pred.append(1)\n",
    "        elif pred12[0,0] == 1 and pred13[0,0] == 1 and pred23[0,0] == 0:\n",
    "            final_pred.append(1)\n",
    "        elif pred12[0,0] == 1 and pred13[0,0] == 1 and pred23[0,0] == 1:\n",
    "            final_pred.append(2)\n",
    "        else:\n",
    "            final_pred.append(-1)\n",
    "    return final_pred\n",
    "\n",
    "final_pred = predictAllClass(testX, p12, p13, p23)\n",
    "\n",
    "def decision_boundary_plot():\n",
    "    x_min, x_max = testX[:, 0].min() - 1, testX[:, 0].max() + 1\n",
    "    y_min, y_max = testX[:, 1].min() - 1, testX[:, 1].max() + 1\n",
    "    h=0.05\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    g_data = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    predictedLabel = predictAllClass(g_data, p12, p13, p23)\n",
    "    color = ['#EE6363', '#BCEE68', '#B2DFEE']\n",
    "    predictedColor = [color[i] for i in predictedLabel]\n",
    "    \n",
    "    plt.scatter(g_data[:,0], g_data[:,1], s=5, color=predictedColor)\n",
    "    plt.scatter(np.array(test1)[:,0], np.array(test1)[:,1], s=5, color='red', label='Class1')\n",
    "    plt.scatter(np.array(test2)[:,0], np.array(test2)[:,1], s=5, color='green', label='Class2')\n",
    "    plt.scatter(np.array(test3)[:,0], np.array(test3)[:,1], s=5, color='blue', label='Class3')\n",
    "    plt.legend(bbox_to_anchor=(0.05, 1.15), loc='upper left', ncol=3)\n",
    "    plt.xlabel('x-axis')\n",
    "    plt.ylabel('y-axis')\n",
    "    # plt.title('Constant density contour plot of Class1, Class2, and Class3 with its dataset')\n",
    "    plt.savefig(\"decision_boundry_Perceptron_LS.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "### Call the 'decision_boundary_plot' function to plot the decision boundary\n",
    "decision_boundary_plot()\n",
    "\n",
    "def epochVsError_plot(model, classes):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    error = model.avg_error\n",
    "    nepoch = [i+1 for i in range(len(error))]\n",
    "    plt.scatter(nepoch, error, marker='o', s=5, facecolors='b', edgecolors='b')\n",
    "    plt.xlabel('Number of Epoch')\n",
    "    plt.ylabel('Average Error')\n",
    "#     plt.title('Average error vs number of epoch for training of Class{} and Class{}'.format(classes[0], classes[1]))\n",
    "    plt.savefig(\"AvgErrorVsEpoch{}{}_Perceptron_LS.png\".format(classes[0], classes[1]), dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "### Call the 'epochVsError_plot' function for all pair of classes\n",
    "epochVsError_plot(p12, [1, 2])\n",
    "epochVsError_plot(p13, [1, 3])\n",
    "epochVsError_plot(p23, [2, 3])\n",
    "\n",
    "### To calculate the confusion matrix and classification accuracy\n",
    "def confusion_matrix(actual, predicted):\n",
    "    cm = np.zeros((3, 3))\n",
    "    for i, j in zip(actual, predicted):\n",
    "        cm[i][j] += 1\n",
    "    ### For classification accuracy\n",
    "    accuracy = np.sum(actual == predicted) * 100.0 / float(len(actual))\n",
    "    return cm, accuracy\n",
    "\n",
    "### Call the confusion_matrix function\n",
    "CM, Accuracy = confusion_matrix(testY, final_pred)\n",
    "print(\"Confusion Matrix: {}\".format(CM))\n",
    "print(\"Classification Accuracy: {}\".format(Accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>For Non Linearly Seperable Data</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[93.  7.  0.]\n",
      " [ 5. 92.  3.]\n",
      " [ 0.  2. 98.]]\n",
      "Classification Accuracy: 94.33333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from perceptron import Perceptron\n",
    "\n",
    "### Create data set by combining the two class data\n",
    "def two_class_data(train1, train2, validate1, validate2, test1, test2):\n",
    "    trainX = np.concatenate((train1, train2), axis=0)\n",
    "    trainY = np.array([0 for i in range(len(train1))] + [1 for i in range(len(train2))])\n",
    "    validateX = np.concatenate((validate1, validate2), axis=0)\n",
    "    validateY = np.array([0 for i in range(len(validate1))] + [1 for i in range(len(validate2))])\n",
    "    testX = np.concatenate((test1, test2), axis=0)\n",
    "    testY = np.array([0 for i in range(len(test1))] + [1 for i in range(len(test2))])\n",
    "    return trainX, trainY, validateX, validateY, testX, testY\n",
    "\n",
    "### Create data set by combining all three class data\n",
    "def all_class_data(train1, train2, train3, validate1, validate2, validate3, test1, test2, test3):\n",
    "    trainX = np.concatenate((train1, train2, train3), axis=0)\n",
    "    trainY = np.array([0 for i in range(len(train1))] + [1 for i in range(len(train2))] + [2 for i in range(len(train3))])\n",
    "    validateX = np.concatenate((validate1, validate2, validate3), axis=0)\n",
    "    validateY = np.array([0 for i in range(len(validate1))] + [1 for i in range(len(validate2))] + [2 for i in range(len(validate3))])\n",
    "    testX = np.concatenate((test1, test2, test3), axis=0)\n",
    "    testY = np.array([0 for i in range(len(test1))] + [1 for i in range(len(test2))] + [2 for i in range(len(test3))])\n",
    "    return trainX, trainY, validateX, validateY, testX, testY\n",
    "\n",
    "#### Path of all class dataset \n",
    "f1 = r\"D:\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Classification\\NLS_Group32.txt\"\n",
    "\n",
    "### Devide the Class1 data into training, validation, and testing data\n",
    "df = pd.read_csv(f1, delimiter=' ', header=None)\n",
    "df1, df2, df3 = np.split(df, [500, 1000])\n",
    "train1, validate1, test1 = np.split(df1, [int(0.6*len(df1)), int(0.8*len(df1))])\n",
    "### Devide the Class2 data into training, validation, and testing data\n",
    "train2, validate2, test2 = np.split(df2, [int(0.6*len(df2)), int(0.8*len(df2))])\n",
    "### Devide the Class3 data into training, validation, and testing data\n",
    "train3, validate3, test3 = np.split(df3, [int(0.6*len(df3)), int(0.8*len(df3))])\n",
    "\n",
    "#### For classification between Class1 and Class2 ####\n",
    "trainX12, trainY12, validateX12, validateY12, testX12, testY12 = two_class_data(train1, train2, validate1, validate2, test1, test2)\n",
    "trainX13, trainY13, validateX13, validateY13, testX13, testY13 = two_class_data(train1, train3, validate1, validate3, test1, test3)\n",
    "trainX23, trainY23, validateX23, validateY23, testX23, testY23 = two_class_data(train2, train3, validate2, validate3, test2, test3)\n",
    "trainX, trainY, validateX, validateY, testX, testY = all_class_data(train1, train2, train3, validate1, validate2, validate3, test1, test2, test3)\n",
    "\n",
    "### Classification between class1 and class2 \n",
    "p12 = Perceptron(learning_rate=0.001, epoch=1000)\n",
    "p12.train(trainX12, trainY12, epoch=True)\n",
    "predictions12 = p12.predict(testX12)\n",
    "\n",
    "### Classification between class3 and class1 \n",
    "p13 = Perceptron(learning_rate=0.001, epoch=1000)\n",
    "p13.train(trainX13, trainY13, epoch=True)\n",
    "predictions13 = p13.predict(testX13)\n",
    "\n",
    "### Classification between class2 and class3 \n",
    "p23 = Perceptron(learning_rate=0.001, epoch=1000)\n",
    "p23.train(trainX23, trainY23, epoch=True)\n",
    "predictions23 = p23.predict(testX23)\n",
    "\n",
    "def predictAllClass(testX, model12, model13, model23):\n",
    "    final_pred = []\n",
    "    for i in range(len(testX)):\n",
    "        x = testX[i:i+1]\n",
    "        pred12 = model12.predict(x)\n",
    "        pred13 = model13.predict(x)\n",
    "        pred23 = model23.predict(x)\n",
    "        if pred12[0,0] == 0 and pred13[0,0] == 0 and pred23[0,0] == 0:\n",
    "            final_pred.append(0)\n",
    "        elif pred12[0,0] == 0 and pred13[0,0] == 0 and pred23[0,0] == 1:\n",
    "            final_pred.append(0)\n",
    "        elif pred12[0,0] == 0 and pred13[0,0] == 1 and pred23[0,0] == 1:\n",
    "            final_pred.append(2)\n",
    "        elif pred12[0,0] == 1 and pred13[0,0] == 0 and pred23[0,0] == 0:\n",
    "            final_pred.append(1)\n",
    "        elif pred12[0,0] == 1 and pred13[0,0] == 1 and pred23[0,0] == 0:\n",
    "            final_pred.append(1)\n",
    "        elif pred12[0,0] == 1 and pred13[0,0] == 1 and pred23[0,0] == 1:\n",
    "            final_pred.append(2)\n",
    "        else:\n",
    "            final_pred.append(-1)\n",
    "    return final_pred\n",
    "\n",
    "final_pred = predictAllClass(testX, p12, p13, p23)\n",
    "\n",
    "def decision_boundary_plot():\n",
    "    x_min, x_max = testX[:, 0].min() - 1, testX[:, 0].max() + 1\n",
    "    y_min, y_max = testX[:, 1].min() - 1, testX[:, 1].max() + 1\n",
    "    h=0.005\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    g_data = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    predictedLabel = predictAllClass(g_data, p12, p13, p23)\n",
    "    color = ['#EE6363', '#BCEE68', '#B2DFEE']\n",
    "    predictedColor = [color[i] for i in predictedLabel]\n",
    "    \n",
    "    plt.scatter(g_data[:,0], g_data[:,1], s=5, color=predictedColor)\n",
    "    plt.scatter(np.array(test1)[:,0], np.array(test1)[:,1], s=5, color='red', label='Class1')\n",
    "    plt.scatter(np.array(test2)[:,0], np.array(test2)[:,1], s=5, color='green', label='Class2')\n",
    "    plt.scatter(np.array(test3)[:,0], np.array(test3)[:,1], s=5, color='blue', label='Class3')\n",
    "    plt.legend(bbox_to_anchor=(0.05, 1.15), loc='upper left', ncol=3)\n",
    "    plt.xlabel('x-axis')\n",
    "    plt.ylabel('y-axis')\n",
    "    # plt.title('Constant density contour plot of Class1, Class2, and Class3 with its dataset')\n",
    "    plt.savefig(\"decision_boundry_Perceptron_NLS.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "### Call the 'decision_boundary_plot' function to plot the decision boundary\n",
    "decision_boundary_plot()\n",
    "\n",
    "def epochVsError_plot(model, classes):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    error = model.avg_error\n",
    "    nepoch = [i+1 for i in range(len(error))]\n",
    "    plt.scatter(nepoch, error, marker='o', s=5, facecolors='b', edgecolors='b')\n",
    "    plt.xlabel('Number of Epoch')\n",
    "    plt.ylabel('Average Error')\n",
    "#     plt.title('Average error vs number of epoch for training of Class{} and Class{}'.format(classes[0], classes[1]))\n",
    "    plt.savefig(\"AvgErrorVsEpoch{}{}_Perceptron_NLS.png\".format(classes[0], classes[1]), dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "### Call the 'epochVsError_plot' function for all pair of classes\n",
    "epochVsError_plot(p12, [1, 2])\n",
    "epochVsError_plot(p13, [1, 3])\n",
    "epochVsError_plot(p23, [2, 3])\n",
    "\n",
    "### To calculate the confusion matrix and classification accuracy\n",
    "def confusion_matrix(actual, predicted):\n",
    "    cm = np.zeros((3, 3))\n",
    "    for i, j in zip(actual, predicted):\n",
    "        cm[i][j] += 1\n",
    "    ### For classification accuracy\n",
    "    accuracy = np.sum(actual == predicted) * 100.0 / float(len(actual))\n",
    "    return cm, accuracy\n",
    "\n",
    "### Call the confusion_matrix function\n",
    "CM, Accuracy = confusion_matrix(testY, final_pred)\n",
    "print(\"Confusion Matrix: {}\".format(CM))\n",
    "print(\"Classification Accuracy: {}\".format(Accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Univariant Regression using single Perceptron</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from perceptron import Perceptron\n",
    "\n",
    "#### Path of Univariant regression dataset \n",
    "f1 = r\"D:\\Sujeet_PhD\\Course_Work\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Regression\\UnivariateData\\32.csv\"\n",
    "\n",
    "### Devide the data into training, validation, and testing data\n",
    "df = pd.read_csv(f1, header=None)\n",
    "train, validate, test = np.split(df, [int(0.6*len(df)), int(0.8*len(df))])\n",
    "trainX, trainY = np.array(train[0]).reshape((train.shape[0], 1)), np.array(train[1])\n",
    "validateX, validateY = np.array(validate[0]).reshape((validate.shape[0], 1)), np.array(validate[1])\n",
    "testX, testY = np.array(test[0]).reshape((test.shape[0], 1)), np.array(test[1])\n",
    "\n",
    "### Classification between class1 and class2 \n",
    "p1 = Perceptron(learning_rate=0.00001, epoch=5000, prediction='regression')\n",
    "p1.train(trainX, trainY, epoch=True)\n",
    "\n",
    "predictions_train = p1.predictR(trainX)\n",
    "predictions_validate = p1.predictR(validateX)\n",
    "predictions_test = p1.predictR(testX)\n",
    "\n",
    "def epochVsError_plot(model):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    error = model.avg_error\n",
    "    nepoch = [i+1 for i in range(len(error))]\n",
    "    plt.scatter(nepoch, error, marker='o', s=5, facecolors='none', edgecolors='b')\n",
    "    plt.xlabel('Number of Epoch')\n",
    "    plt.ylabel('Average Error')\n",
    "#     plt.title('Average error vs number of epoch for training of univariant regression data')\n",
    "    plt.savefig(\"AvgErrorVsEpoch_Perceptron_Regression1.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "    \n",
    "def modelAndTarget_plot(target, model, label='train'):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    n_item = [i+1 for i in range(len(target))]\n",
    "    plt.scatter(n_item, model, marker='o', s=5, facecolors='b', edgecolors='b', label='Model Output')\n",
    "    plt.scatter(n_item, target, marker='s', s=5, facecolors='r', edgecolors='r', label='Target Output')\n",
    "    plt.legend(bbox_to_anchor=(0.15, 1.2), loc='upper left', ncol=2)\n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel('Regression Output')\n",
    "#     plt.title('Model output and target output of {} dataset'.format(label))\n",
    "    plt.savefig(\"modelAndTarget_{}_Perceptron_Regression1.png\".format(label), dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "def modelVsTarget_plot(target, model, label='train'):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(target, model, marker='o', s=5, facecolors='b', edgecolors='b')\n",
    "    plt.xlabel('Target Output')\n",
    "    plt.ylabel('Model Output')\n",
    "#     plt.title('Model output vs target output of {} dataset'.format(label))\n",
    "    plt.savefig(\"modelVsTarget_{}_Perceptron_Regression1.png\".format(label), dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "    \n",
    "def MSE(target, model):\n",
    "    target = np.array(target)\n",
    "    model = np.array(model)\n",
    "    mse = np.mean(np.power(target - model, 2))\n",
    "    return mse\n",
    "\n",
    "def plot_mse(mse):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    x_data = ['train', 'validation', 'test']\n",
    "    plt.scatter(x_data, mse, marker='o', s=5, facecolors='b', edgecolors='b')\n",
    "    plt.xlabel('Type of Dataset')\n",
    "    plt.ylabel('Mean Square Error')\n",
    "#     plt.title('Mean squared error (MSE) on training data, validation data and test data')\n",
    "    plt.savefig(\"MSE_Perceptron_Regression1.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "    \n",
    "### Call the 'epochVsError_plot' function for all pair of classes\n",
    "epochVsError_plot(p1)\n",
    "### Model output and target output plot\n",
    "modelAndTarget_plot(trainY, predictions_train, label='train')\n",
    "modelAndTarget_plot(testY, predictions_test, label='test')\n",
    "modelAndTarget_plot(validateY, predictions_validate, label='validation')\n",
    "### Model output vs target output plot\n",
    "modelVsTarget_plot(trainY, predictions_train, label='train')\n",
    "modelVsTarget_plot(testY, predictions_test, label='test')\n",
    "modelVsTarget_plot(validateY, predictions_validate, label='validation')\n",
    "### For Mean square Error\n",
    "mse_train = MSE(trainY, predictions_train)\n",
    "mse_val = MSE(validateY, predictions_validate)\n",
    "mse_test = MSE(testY, predictions_test)\n",
    "plot_mse([mse_train, mse_val, mse_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Multivariant Regression using single Perceptron</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from perceptron import Perceptron\n",
    "\n",
    "#### Path of Bivariant regression dataset \n",
    "f1 = r\"D:\\DeepLearning (CS671)\\Assignment\\Assignment1\\dataset\\Group32\\Regression\\BivariateData\\32.csv\"\n",
    "\n",
    "### Devide the data into training, validation, and testing data\n",
    "df = pd.read_csv(f1, header=None)\n",
    "train, validate, test = np.split(df, [int(0.6*len(df)), int(0.8*len(df))])\n",
    "trainX, trainY = train.to_numpy()[:,0:2].reshape((train.shape[0], 2)), train.to_numpy()[:,2]\n",
    "validateX, validateY = validate.to_numpy()[:,0:2].reshape((validate.shape[0], 2)), validate.to_numpy()[:,2]\n",
    "testX, testY = test.to_numpy()[:,0:2].reshape((test.shape[0], 2)), test.to_numpy()[:,2]\n",
    "\n",
    "### Classification between class1 and class2 \n",
    "p2 = Perceptron(learning_rate=0.00001, epoch=5000, prediction='regression')\n",
    "p2.train(trainX, trainY, epoch=True)\n",
    "\n",
    "predictions_train = p2.predictR(trainX)\n",
    "predictions_validate = p2.predictR(validateX)\n",
    "predictions_test = p2.predictR(testX)\n",
    "\n",
    "def epochVsError_plot(model):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    error = model.avg_error\n",
    "    nepoch = [i+1 for i in range(len(error))]\n",
    "    plt.scatter(nepoch, error, marker='o', s=5, facecolors='b', edgecolors='b')\n",
    "    plt.xlabel('Number of Epoch')\n",
    "    plt.ylabel('Average Error')\n",
    "#     plt.title('Average error vs number of epoch for training of Bivariant regression data')\n",
    "    plt.savefig(\"AvgErrorVsEpoch_Perceptron_Regression2.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "    \n",
    "def modelAndTarget_plot(target, model, label='train'):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    n_item = [i+1 for i in range(len(target))]\n",
    "    plt.scatter(n_item, model, marker='o', s=5, facecolors='b', edgecolors='b', label='Model Output')\n",
    "    plt.scatter(n_item, target, marker='s', s=5, facecolors='r', edgecolors='r', label='Target Output')\n",
    "    plt.legend(bbox_to_anchor=(0.15, 1.2), loc='upper left', ncol=2)\n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel('Regression Output')\n",
    "#     plt.title('Model output and target output of {} dataset'.format(label))\n",
    "    plt.savefig(\"modelAndTarget_{}_Perceptron_Regression2.png\".format(label), dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "def modelVsTarget_plot(target, model, label='train'):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(target, model, marker='o', s=5, facecolors='b', edgecolors='b')\n",
    "    plt.xlabel('Target Output')\n",
    "    plt.ylabel('Model Output')\n",
    "#     plt.title('Model output vs target output of {} dataset'.format(label))\n",
    "    plt.savefig(\"modelVsTarget_{}_Perceptron_Regression2.png\".format(label), dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "def MSE(target, model):\n",
    "    target = np.array(target)\n",
    "    model = np.array(model)\n",
    "    mse = np.mean(np.power(target - model, 2))\n",
    "    return mse\n",
    "\n",
    "def plot_mse(mse):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    x_data = ['train', 'validation', 'test']\n",
    "    plt.scatter(x_data, mse, marker='o', s=5, facecolors='b', edgecolors='b')\n",
    "    plt.xlabel('Type of Dataset')\n",
    "    plt.ylabel('Mean Square Error')\n",
    "#     plt.title('Mean squared error (MSE) on training data, validation data and test data')\n",
    "    plt.savefig(\"MSE_Perceptron_Regression2.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "    \n",
    "### Call the 'epochVsError_plot' function for all pair of classes\n",
    "epochVsError_plot(p2)\n",
    "### Model output and target output plot\n",
    "modelAndTarget_plot(trainY, predictions_train, label='train')\n",
    "modelAndTarget_plot(testY, predictions_test, label='test')\n",
    "modelAndTarget_plot(validateY, predictions_validate, label='validation')\n",
    "### Model output vs target output plot\n",
    "modelVsTarget_plot(trainY, predictions_train, label='train')\n",
    "modelVsTarget_plot(testY, predictions_test, label='test')\n",
    "modelVsTarget_plot(validateY, predictions_validate, label='validation')\n",
    "### For Mean square Error\n",
    "mse_train = MSE(trainY, predictions_train)\n",
    "mse_val = MSE(validateY, predictions_validate)\n",
    "mse_test = MSE(testY, predictions_test)\n",
    "plot_mse([mse_train, mse_val, mse_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
